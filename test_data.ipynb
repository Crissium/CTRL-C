{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "proud-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "import datasets\n",
    "from datasets import build_dataset\n",
    "import util.misc as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "following-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser('Set transformer detector', add_help=False)\n",
    "    parser.add_argument('--lr', default=1e-4, type=float)\n",
    "    parser.add_argument('--lr_backbone', default=1e-5, type=float)\n",
    "    parser.add_argument('--batch_size', default=100, type=int)\n",
    "    parser.add_argument('--weight_decay', default=1e-4, type=float)\n",
    "    parser.add_argument('--epochs', default=50, type=int)\n",
    "    parser.add_argument('--lr_drop', default=20, type=int)\n",
    "    parser.add_argument('--clip_max_norm', default=0.1, type=float,\n",
    "                        help='gradient clipping max norm')\n",
    "    \n",
    "    # * Backbone\n",
    "    parser.add_argument('--backbone', default='resnet50', type=str,\n",
    "                        help=\"Name of the convolutional backbone to use\")\n",
    "    parser.add_argument('--dilation', action='store_true',\n",
    "                        help=\"If true, we replace stride with dilation in the last convolutional block (DC5)\")\n",
    "    parser.add_argument('--position_embedding', default='sine', type=str, choices=('sine', 'learned'),\n",
    "                        help=\"Type of positional embedding to use on top of the image features\")\n",
    "\n",
    "    # * Transformer\n",
    "    parser.add_argument('--enc_layers', default=6, type=int,\n",
    "                        help=\"Number of encoding layers in the transformer\")\n",
    "    parser.add_argument('--dec_layers', default=6, type=int,\n",
    "                        help=\"Number of decoding layers in the transformer\")\n",
    "    parser.add_argument('--dim_feedforward', default=2048, type=int,\n",
    "                        help=\"Intermediate size of the feedforward layers in the transformer blocks\")\n",
    "    parser.add_argument('--hidden_dim', default=256, type=int,\n",
    "                        help=\"Size of the embeddings (dimension of the transformer)\")\n",
    "    parser.add_argument('--dropout', default=0.1, type=float,\n",
    "                        help=\"Dropout applied in the transformer\")\n",
    "    parser.add_argument('--nheads', default=8, type=int,\n",
    "                        help=\"Number of attention heads inside the transformer's attentions\")\n",
    "    parser.add_argument('--num_queries', default=3, type=int,\n",
    "                        help=\"Number of query slots\")\n",
    "    parser.add_argument('--pre_norm', action='store_true')\n",
    "    \n",
    "    # * Segmentation\n",
    "    parser.add_argument('--masks', action='store_true',\n",
    "                        help=\"Train segmentation head if the flag is provided\")\n",
    "\n",
    "    # Loss\n",
    "    parser.add_argument('--no_aux_loss', dest='aux_loss', action='store_false',\n",
    "                        help=\"Disables auxiliary decoding losses (loss at each layer)\")\n",
    "    \n",
    "    # dataset parameters\n",
    "    parser.add_argument('--input_width', default=512, type=int)\n",
    "    parser.add_argument('--input_height', default=512, type=int)    \n",
    "    \n",
    "    parser.add_argument('--output_dir', default='output',\n",
    "                        help='path where to save, empty for no saving')\n",
    "    parser.add_argument('--device', default='cuda',\n",
    "                        help='device to use for training / testing')\n",
    "\n",
    "    # display\n",
    "    parser.add_argument('--display', default=True,\n",
    "                        help='choose whether visualize image')\n",
    "    return parser\n",
    "\n",
    "args = get_args_parser().parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "atlantic-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = build_dataset(image_set='test', args=args)\n",
    "sampler_test = torch.utils.data.SequentialSampler(dataset_test)\n",
    "data_loader_test = DataLoader(dataset_test, 1, sampler=sampler_test,\n",
    "                             drop_last=False, \n",
    "                             collate_fn=utils.collate_fn, \n",
    "                             num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "direct-actor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['rp', 'fovy', 'up_vector', 'focal', 'zvp', 'hl', 'org_img', 'org_sz', 'input_sz', 'img_path', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "img, target = dataset_test[128]\n",
    "print(target.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fewer-publisher",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4281]) torch.Size([1])\n",
      "tensor([1.7051, 5.9464, 1.0000]) torch.Size([3])\n",
      "tensor([-0.2686, -0.9366, -0.3213]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "focal = target['focal']\n",
    "zvp = target['zvp']\n",
    "hl = target['hl']\n",
    "print(focal, focal.size())\n",
    "print(zvp, zvp.size())\n",
    "print(hl, hl.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "simple-departure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.0396)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zvp[1]*(-hl[2]/hl[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "quantitative-saturday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0396])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "focal*focal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "diagnostic-notice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4579, -5.5695, -0.3213])\n",
      "tensor(-6.3487)\n"
     ]
    }
   ],
   "source": [
    "print(zvp*hl)\n",
    "print(torch.sum(zvp*hl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "alone-forwarding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7051, 5.9464, 1.4281])\n",
      "tensor([-0.3836, -1.3376, -0.3213])\n"
     ]
    }
   ],
   "source": [
    "zvp_focal = zvp.clone()\n",
    "zvp_focal[2] = focal[0]\n",
    "print(zvp_focal)\n",
    "\n",
    "hl_focal = hl.clone()\n",
    "hl_focal[0:2] *= focal[0]\n",
    "print(hl_focal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "executed-thread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6540, -7.9541, -0.4588])\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "print(zvp_focal*hl_focal)\n",
    "cossim = F.cosine_similarity(zvp_focal, hl_focal, dim=-1).abs()\n",
    "print(1.0 - cossim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "strange-likelihood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict_keys'>\n",
      "['a', 'b', 'c', 'd']\n"
     ]
    }
   ],
   "source": [
    "dic = {'c': 0, 'd': 0}\n",
    "print(type(dic.keys()))\n",
    "lst = ['a','b'] + list(dic.keys())\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-liver",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
